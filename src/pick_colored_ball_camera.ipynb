{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Imports loaded\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import time\n",
    "from pydrake.all import (\n",
    "    DiagramBuilder,\n",
    "    Simulator,\n",
    "    StartMeshcat,\n",
    "    RigidTransform,\n",
    "    RotationMatrix,\n",
    "    Sphere,\n",
    "    Box,\n",
    "    RollPitchYaw,\n",
    "    InverseKinematics,\n",
    "    Solve,\n",
    "    MakeRenderEngineVtk,\n",
    "    RenderEngineVtkParams,\n",
    ")\n",
    "from pydrake.geometry import Rgba\n",
    "from pydrake.systems.sensors import RgbdSensor, CameraConfig\n",
    "from manipulation.station import LoadScenario, MakeHardwareStation\n",
    "\n",
    "print(\"✓ Imports loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:drake:Meshcat listening for connections at http://localhost:7001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meshcat: http://localhost:7001\n"
     ]
    }
   ],
   "source": [
    "meshcat = StartMeshcat()\n",
    "print(f\"Meshcat: {meshcat.web_url()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perception functions\n",
    "\n",
    "def depth_image_to_point_cloud(depth_image, rgb_image, camera_info):\n",
    "    \"\"\"Convert depth image to colored point cloud in camera frame\"\"\"\n",
    "    height, width = depth_image.shape\n",
    "    fx = camera_info.focal_x()\n",
    "    fy = camera_info.focal_y()\n",
    "    cx = camera_info.center_x()\n",
    "    cy = camera_info.center_y()\n",
    "    \n",
    "    # Pixel grid\n",
    "    u = np.arange(width)\n",
    "    v = np.arange(height)\n",
    "    u_grid, v_grid = np.meshgrid(u, v)\n",
    "    \n",
    "    # Valid depth mask\n",
    "    valid = (depth_image > 0.01) & (depth_image < 5.0)\n",
    "    \n",
    "    u_valid = u_grid[valid]\n",
    "    v_valid = v_grid[valid]\n",
    "    z_valid = depth_image[valid]\n",
    "    \n",
    "    # Back-project to 3D (camera frame: X right, Y down, Z forward)\n",
    "    x = (u_valid - cx) * z_valid / fx\n",
    "    y = (v_valid - cy) * z_valid / fy\n",
    "    z = z_valid\n",
    "    \n",
    "    points = np.column_stack([x, y, z])\n",
    "    colors = rgb_image[valid].astype(float) / 255.0\n",
    "    \n",
    "    return points, colors\n",
    "\n",
    "\n",
    "def transform_points_to_world(points, X_CameraToWorld):\n",
    "    \"\"\"Transform points from camera frame to world frame\"\"\"\n",
    "    points_world = []\n",
    "    for pt in points:\n",
    "        pt_world = X_CameraToWorld @ pt\n",
    "        points_world.append(pt_world)\n",
    "    return np.array(points_world)\n",
    "\n",
    "\n",
    "def segment_red_color(points, colors, red_min=0.5, other_max=0.35):\n",
    "    \"\"\"Segment red points using color thresholds\"\"\"\n",
    "    is_red = (\n",
    "        (colors[:, 0] > red_min) &      # R > 0.5\n",
    "        (colors[:, 1] < other_max) &    # G < 0.35\n",
    "        (colors[:, 2] < other_max)      # B < 0.35\n",
    "    )\n",
    "    return points[is_red]\n",
    "\n",
    "\n",
    "def compute_ball_center(points):\n",
    "    \"\"\"Compute centroid of point cluster\"\"\"\n",
    "    if len(points) == 0:\n",
    "        return None\n",
    "    return np.mean(points, axis=0)\n",
    "\n",
    "\n",
    "def simulate_rgbd_capture(camera_info, X_WorldToCamera, ball_positions, ball_colors, ball_radius=0.05):\n",
    "    \"\"\"Simulate RGB-D camera seeing balls (for testing without real scene graph objects)\"\"\"\n",
    "    width = camera_info.width()\n",
    "    height = camera_info.height()\n",
    "    fx = camera_info.focal_x()\n",
    "    fy = camera_info.focal_y()\n",
    "    cx = camera_info.center_x()\n",
    "    cy = camera_info.center_y()\n",
    "    \n",
    "    # Initialize images\n",
    "    rgb_image = np.ones((height, width, 3), dtype=np.uint8) * 50  # Dark background\n",
    "    depth_image = np.zeros((height, width), dtype=np.float32)\n",
    "    \n",
    "    # Transform balls to camera frame\n",
    "    X_CameraToWorld = X_WorldToCamera.inverse()\n",
    "    \n",
    "    for ball_pos, ball_color in zip(ball_positions, ball_colors):\n",
    "        ball_in_camera = X_CameraToWorld @ ball_pos\n",
    "        \n",
    "        if ball_in_camera[2] <= 0:\n",
    "            continue\n",
    "        \n",
    "        u_center = fx * ball_in_camera[0] / ball_in_camera[2] + cx\n",
    "        v_center = fy * ball_in_camera[1] / ball_in_camera[2] + cy\n",
    "        radius_px = int(fx * ball_radius / ball_in_camera[2])\n",
    "        \n",
    "        for v in range(max(0, int(v_center - radius_px)), min(height, int(v_center + radius_px))):\n",
    "            for u in range(max(0, int(u_center - radius_px)), min(width, int(u_center + radius_px))):\n",
    "                du = u - u_center\n",
    "                dv = v - v_center\n",
    "                \n",
    "                if du**2 + dv**2 < radius_px**2:\n",
    "                    offset_from_center = np.sqrt(du**2 + dv**2) / radius_px\n",
    "                    if offset_from_center < 1.0:\n",
    "                        depth_offset = ball_radius * np.sqrt(1 - offset_from_center**2)\n",
    "                        depth = ball_in_camera[2] - depth_offset\n",
    "                        rgb_image[v, u] = ball_color\n",
    "                        depth_image[v, u] = depth\n",
    "    \n",
    "    return rgb_image, depth_image\n",
    "\n",
    "\n",
    "# Manipulation functions\n",
    "\n",
    "def compute_sphere_grasp(ball_center, ball_radius):\n",
    "    \"\"\"Compute top-down grasp pose for sphere\"\"\"\n",
    "    finger_depth = 0.01\n",
    "    grasp_height = ball_radius + finger_depth\n",
    "    p_WG = ball_center + np.array([0, 0, grasp_height])\n",
    "    R_WG = RotationMatrix(RollPitchYaw([np.pi, 0, 0]))\n",
    "    X_WG = RigidTransform(R_WG, p_WG)\n",
    "    return X_WG\n",
    "\n",
    "\n",
    "def normalize_joint_angles(q_start, q_end):\n",
    "    \"\"\"Normalize joint angles to take shortest path (prevents 360 spins!)\n",
    "    \n",
    "    For each joint, if the difference is > π, adjust by 2π to take shorter path.\n",
    "    \"\"\"\n",
    "    q_end_normalized = q_end.copy()\n",
    "    for i in range(len(q_start)):\n",
    "        diff = q_end[i] - q_start[i]\n",
    "        # If difference is > π, we're going the long way around\n",
    "        if diff > np.pi:\n",
    "            q_end_normalized[i] -= 2 * np.pi\n",
    "        elif diff < -np.pi:\n",
    "            q_end_normalized[i] += 2 * np.pi\n",
    "    return q_end_normalized\n",
    "\n",
    "\n",
    "def solve_ik_position_priority(plant, plant_context, target_position, \n",
    "                                 orientation_target=None, pos_tol=0.005):\n",
    "    \"\"\"IK solver prioritizing position over strict orientation\n",
    "    \n",
    "    Note: Bin collision geometry exists in scene graph, so the robot\n",
    "    will respect it during execution even if IK doesn't explicitly check.\n",
    "    We ensure collision-free paths by approaching from above.\n",
    "    \"\"\"\n",
    "    ik = InverseKinematics(plant, plant_context)\n",
    "    gripper_frame = plant.GetFrameByName(\"body\")\n",
    "    \n",
    "    # Position constraint\n",
    "    ik.AddPositionConstraint(\n",
    "        gripper_frame, [0, 0, 0], plant.world_frame(),\n",
    "        target_position - pos_tol, target_position + pos_tol\n",
    "    )\n",
    "    \n",
    "    # Orientation constraint\n",
    "    if orientation_target is not None:\n",
    "        if isinstance(orientation_target, RigidTransform):\n",
    "            orientation_target = orientation_target.rotation()\n",
    "        ik.AddOrientationConstraint(\n",
    "            gripper_frame, RotationMatrix(), plant.world_frame(),\n",
    "            orientation_target, 0.3\n",
    "        )\n",
    "    \n",
    "    # Cost to stay near current configuration (increased to discourage large movements)\n",
    "    q_nominal = plant.GetPositions(plant_context, plant.GetModelInstanceByName(\"iiwa\"))\n",
    "    ik.prog().AddQuadraticErrorCost(np.eye(7) * 50.0, q_nominal, ik.q())  # Increased from 5.0\n",
    "    \n",
    "    result = Solve(ik.prog())\n",
    "    if result.is_success():\n",
    "        return True, result.GetSolution(ik.q())\n",
    "    return False, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build scene with robot, gripper, 3 CAMERAS, AND BIN WITH COLLISION\n",
    "\n",
    "# First, create SDF files for balls and bin\n",
    "import tempfile\n",
    "import os\n",
    "\n",
    "# Create temporary directory for SDF files\n",
    "temp_dir = tempfile.mkdtemp()\n",
    "\n",
    "# Red ball SDF\n",
    "red_ball_sdf = \"\"\"<?xml version=\"1.0\"?>\n",
    "<sdf version=\"1.7\">\n",
    "  <model name=\"red_ball\">\n",
    "    <link name=\"ball\">\n",
    "      <inertial>\n",
    "        <mass>0.1</mass>\n",
    "        <inertia>\n",
    "          <ixx>0.0001</ixx>\n",
    "          <ixy>0</ixy>\n",
    "          <ixz>0</ixz>\n",
    "          <iyy>0.0001</iyy>\n",
    "          <iyz>0</iyz>\n",
    "          <izz>0.0001</izz>\n",
    "        </inertia>\n",
    "      </inertial>\n",
    "      <visual name=\"visual\">\n",
    "        <geometry>\n",
    "          <sphere>\n",
    "            <radius>0.05</radius>\n",
    "          </sphere>\n",
    "        </geometry>\n",
    "        <material>\n",
    "          <diffuse>0.9 0.1 0.1 1.0</diffuse>\n",
    "        </material>\n",
    "      </visual>\n",
    "      <collision name=\"collision\">\n",
    "        <geometry>\n",
    "          <sphere>\n",
    "            <radius>0.05</radius>\n",
    "          </sphere>\n",
    "        </geometry>\n",
    "      </collision>\n",
    "    </link>\n",
    "  </model>\n",
    "</sdf>\n",
    "\"\"\"\n",
    "\n",
    "# Blue ball SDF\n",
    "blue_ball_sdf = \"\"\"<?xml version=\"1.0\"?>\n",
    "<sdf version=\"1.7\">\n",
    "  <model name=\"blue_ball\">\n",
    "    <link name=\"ball\">\n",
    "      <inertial>\n",
    "        <mass>0.1</mass>\n",
    "        <inertia>\n",
    "          <ixx>0.0001</ixx>\n",
    "          <ixy>0</ixy>\n",
    "          <ixz>0</ixz>\n",
    "          <iyy>0.0001</iyy>\n",
    "          <iyz>0</iyz>\n",
    "          <izz>0.0001</izz>\n",
    "        </inertia>\n",
    "      </inertial>\n",
    "      <visual name=\"visual\">\n",
    "        <geometry>\n",
    "          <sphere>\n",
    "            <radius>0.05</radius>\n",
    "          </sphere>\n",
    "        </geometry>\n",
    "        <material>\n",
    "          <diffuse>0.2 0.4 0.9 1.0</diffuse>\n",
    "        </material>\n",
    "      </visual>\n",
    "      <collision name=\"collision\">\n",
    "        <geometry>\n",
    "          <sphere>\n",
    "            <radius>0.05</radius>\n",
    "          </sphere>\n",
    "        </geometry>\n",
    "      </collision>\n",
    "    </link>\n",
    "  </model>\n",
    "</sdf>\n",
    "\"\"\"\n",
    "\n",
    "# Bin SDF with COLLISION geometry\n",
    "# Note: static=true automatically welds to world, no explicit weld needed\n",
    "bin_sdf = \"\"\"<?xml version=\"1.0\"?>\n",
    "<sdf version=\"1.7\">\n",
    "  <model name=\"bin\">\n",
    "    <pose>0 -0.6 0 0 0 0</pose>\n",
    "    <static>true</static>\n",
    "    \n",
    "    <!-- Floor -->\n",
    "    <link name=\"floor\">\n",
    "      <pose>0 0 0 0 0 0</pose>\n",
    "      <inertial>\n",
    "        <mass>1.0</mass>\n",
    "        <inertia>\n",
    "          <ixx>0.01</ixx>\n",
    "          <ixy>0</ixy>\n",
    "          <ixz>0</ixz>\n",
    "          <iyy>0.01</iyy>\n",
    "          <iyz>0</iyz>\n",
    "          <izz>0.01</izz>\n",
    "        </inertia>\n",
    "      </inertial>\n",
    "      <visual name=\"visual\">\n",
    "        <geometry>\n",
    "          <box>\n",
    "            <size>0.25 0.25 0.01</size>\n",
    "          </box>\n",
    "        </geometry>\n",
    "        <material>\n",
    "          <diffuse>0.6 0.4 0.3 1.0</diffuse>\n",
    "        </material>\n",
    "      </visual>\n",
    "      <collision name=\"collision\">\n",
    "        <geometry>\n",
    "          <box>\n",
    "            <size>0.25 0.25 0.01</size>\n",
    "          </box>\n",
    "        </geometry>\n",
    "      </collision>\n",
    "    </link>\n",
    "    \n",
    "    <!-- Front wall -->\n",
    "    <link name=\"front\">\n",
    "      <pose>0 -0.125 0.04 0 0 0</pose>\n",
    "      <inertial>\n",
    "        <mass>0.5</mass>\n",
    "        <inertia>\n",
    "          <ixx>0.01</ixx>\n",
    "          <ixy>0</ixy>\n",
    "          <ixz>0</ixz>\n",
    "          <iyy>0.01</iyy>\n",
    "          <iyz>0</iyz>\n",
    "          <izz>0.01</izz>\n",
    "        </inertia>\n",
    "      </inertial>\n",
    "      <visual name=\"visual\">\n",
    "        <geometry>\n",
    "          <box>\n",
    "            <size>0.25 0.01 0.08</size>\n",
    "          </box>\n",
    "        </geometry>\n",
    "        <material>\n",
    "          <diffuse>0.6 0.4 0.3 1.0</diffuse>\n",
    "        </material>\n",
    "      </visual>\n",
    "      <collision name=\"collision\">\n",
    "        <geometry>\n",
    "          <box>\n",
    "            <size>0.25 0.01 0.08</size>\n",
    "          </box>\n",
    "        </geometry>\n",
    "      </collision>\n",
    "    </link>\n",
    "    \n",
    "    <!-- Back wall -->\n",
    "    <link name=\"back\">\n",
    "      <pose>0 0.125 0.04 0 0 0</pose>\n",
    "      <inertial>\n",
    "        <mass>0.5</mass>\n",
    "        <inertia>\n",
    "          <ixx>0.01</ixx>\n",
    "          <ixy>0</ixy>\n",
    "          <ixz>0</ixz>\n",
    "          <iyy>0.01</iyy>\n",
    "          <iyz>0</iyz>\n",
    "          <izz>0.01</izz>\n",
    "        </inertia>\n",
    "      </inertial>\n",
    "      <visual name=\"visual\">\n",
    "        <geometry>\n",
    "          <box>\n",
    "            <size>0.25 0.01 0.08</size>\n",
    "          </box>\n",
    "        </geometry>\n",
    "        <material>\n",
    "          <diffuse>0.6 0.4 0.3 1.0</diffuse>\n",
    "        </material>\n",
    "      </visual>\n",
    "      <collision name=\"collision\">\n",
    "        <geometry>\n",
    "          <box>\n",
    "            <size>0.25 0.01 0.08</size>\n",
    "          </box>\n",
    "        </geometry>\n",
    "      </collision>\n",
    "    </link>\n",
    "    \n",
    "    <!-- Left wall -->\n",
    "    <link name=\"left\">\n",
    "      <pose>-0.125 0 0.04 0 0 0</pose>\n",
    "      <inertial>\n",
    "        <mass>0.5</mass>\n",
    "        <inertia>\n",
    "          <ixx>0.01</ixx>\n",
    "          <ixy>0</ixy>\n",
    "          <ixz>0</ixz>\n",
    "          <iyy>0.01</iyy>\n",
    "          <iyz>0</iyz>\n",
    "          <izz>0.01</izz>\n",
    "        </inertia>\n",
    "      </inertial>\n",
    "      <visual name=\"visual\">\n",
    "        <geometry>\n",
    "          <box>\n",
    "            <size>0.01 0.25 0.08</size>\n",
    "          </box>\n",
    "        </geometry>\n",
    "        <material>\n",
    "          <diffuse>0.6 0.4 0.3 1.0</diffuse>\n",
    "        </material>\n",
    "      </visual>\n",
    "      <collision name=\"collision\">\n",
    "        <geometry>\n",
    "          <box>\n",
    "            <size>0.01 0.25 0.08</size>\n",
    "          </box>\n",
    "        </geometry>\n",
    "      </collision>\n",
    "    </link>\n",
    "    \n",
    "    <!-- Right wall -->\n",
    "    <link name=\"right\">\n",
    "      <pose>0.125 0 0.04 0 0 0</pose>\n",
    "      <inertial>\n",
    "        <mass>0.5</mass>\n",
    "        <inertia>\n",
    "          <ixx>0.01</ixx>\n",
    "          <ixy>0</ixy>\n",
    "          <ixz>0</ixz>\n",
    "          <iyy>0.01</iyy>\n",
    "          <iyz>0</iyz>\n",
    "          <izz>0.01</izz>\n",
    "        </inertia>\n",
    "      </inertial>\n",
    "      <visual name=\"visual\">\n",
    "        <geometry>\n",
    "          <box>\n",
    "            <size>0.01 0.25 0.08</size>\n",
    "          </box>\n",
    "        </geometry>\n",
    "        <material>\n",
    "          <diffuse>0.6 0.4 0.3 1.0</diffuse>\n",
    "        </material>\n",
    "      </visual>\n",
    "      <collision name=\"collision\">\n",
    "        <geometry>\n",
    "          <box>\n",
    "            <size>0.01 0.25 0.08</size>\n",
    "          </box>\n",
    "        </geometry>\n",
    "      </collision>\n",
    "    </link>\n",
    "  </model>\n",
    "</sdf>\n",
    "\"\"\"\n",
    "\n",
    "# Write SDF files\n",
    "red_ball_path = os.path.join(temp_dir, \"red_ball.sdf\")\n",
    "blue_ball_path = os.path.join(temp_dir, \"blue_ball.sdf\")\n",
    "bin_path = os.path.join(temp_dir, \"bin.sdf\")\n",
    "\n",
    "with open(red_ball_path, 'w') as f:\n",
    "    f.write(red_ball_sdf)\n",
    "    \n",
    "with open(blue_ball_path, 'w') as f:\n",
    "    f.write(blue_ball_sdf)\n",
    "    \n",
    "with open(bin_path, 'w') as f:\n",
    "    f.write(bin_sdf)\n",
    "\n",
    "# Ball positions\n",
    "red_pos = np.array([0.05, -0.55, 0.04])\n",
    "blue_pos = np.array([-0.05, -0.65, 0.04])\n",
    "\n",
    "# Robot and gripper scenario WITH BALLS AND BIN\n",
    "# Note: bin is static so no explicit weld needed\n",
    "scenario_yaml = f\"\"\"\n",
    "directives:\n",
    "- add_model:\n",
    "    name: iiwa\n",
    "    file: package://drake_models/iiwa_description/urdf/iiwa14_primitive_collision.urdf\n",
    "    default_joint_positions:\n",
    "      iiwa_joint_1: [-1.57]\n",
    "      iiwa_joint_2: [0.1]\n",
    "      iiwa_joint_3: [0]\n",
    "      iiwa_joint_4: [-1.2]\n",
    "      iiwa_joint_5: [0]\n",
    "      iiwa_joint_6: [1.6]\n",
    "      iiwa_joint_7: [0]\n",
    "- add_weld:\n",
    "    parent: world\n",
    "    child: iiwa::iiwa_link_0\n",
    "- add_model:\n",
    "    name: wsg\n",
    "    file: package://drake_models/wsg_50_description/sdf/schunk_wsg_50_welded_fingers.sdf\n",
    "- add_weld:\n",
    "    parent: iiwa::iiwa_link_7\n",
    "    child: wsg::body\n",
    "    X_PC:\n",
    "      translation: [0, 0, 0.09]\n",
    "      rotation: !Rpy {{ deg: [90, 0, 90] }}\n",
    "- add_model:\n",
    "    name: bin\n",
    "    file: file://{bin_path}\n",
    "- add_model:\n",
    "    name: red_ball\n",
    "    file: file://{red_ball_path}\n",
    "- add_weld:\n",
    "    parent: world\n",
    "    child: red_ball::ball\n",
    "    X_PC:\n",
    "      translation: [{red_pos[0]}, {red_pos[1]}, {red_pos[2]}]\n",
    "- add_model:\n",
    "    name: blue_ball\n",
    "    file: file://{blue_ball_path}\n",
    "- add_weld:\n",
    "    parent: world\n",
    "    child: blue_ball::ball\n",
    "    X_PC:\n",
    "      translation: [{blue_pos[0]}, {blue_pos[1]}, {blue_pos[2]}]\n",
    "\"\"\"\n",
    "\n",
    "scenario = LoadScenario(data=scenario_yaml)\n",
    "builder = DiagramBuilder()\n",
    "\n",
    "# Add hardware station\n",
    "station = MakeHardwareStation(scenario, meshcat=meshcat)\n",
    "builder.AddSystem(station)\n",
    "\n",
    "# Get scene graph and add a renderer for the camera\n",
    "scene_graph = station.GetSubsystemByName(\"scene_graph\")\n",
    "\n",
    "# Add VTK renderer to scene graph\n",
    "renderer_name = \"my_renderer\"\n",
    "params = RenderEngineVtkParams()\n",
    "renderer = MakeRenderEngineVtk(params)\n",
    "scene_graph.AddRenderer(renderer_name, renderer)\n",
    "\n",
    "# Camera setup using CameraConfig\n",
    "width, height = 640, 480\n",
    "\n",
    "camera_config = CameraConfig()\n",
    "camera_config.width = width\n",
    "camera_config.height = height\n",
    "camera_config.fps = 10.0\n",
    "camera_config.renderer_name = renderer_name\n",
    "\n",
    "# Helper function to create camera transform\n",
    "def make_camera_transform(camera_pos, look_at_pos):\n",
    "    \"\"\"Create camera transform that looks from camera_pos to look_at_pos\"\"\"\n",
    "    forward = look_at_pos - camera_pos\n",
    "    forward = forward / np.linalg.norm(forward)\n",
    "    world_up = np.array([0, 0, 1])\n",
    "    right = np.cross(forward, world_up)\n",
    "    right = right / np.linalg.norm(right)\n",
    "    down = np.cross(forward, right)\n",
    "    R_WorldToCamera = RotationMatrix(np.column_stack([right, down, forward]))\n",
    "    return RigidTransform(R_WorldToCamera, camera_pos)\n",
    "\n",
    "# Define 3 camera positions SPREAD AROUND the workspace (not coplanar!)\n",
    "# Bin is at y=-0.6, so we position cameras at different angles AROUND it\n",
    "workspace_center = np.array([0.0, -0.6, 0.05])\n",
    "\n",
    "# Camera 1: Front-right, high angle (looking from +x, +y direction)\n",
    "camera_1_pos = np.array([0.35, -0.25, 0.5])\n",
    "\n",
    "# Camera 2: Back-left, low angle (looking from -x, -y direction - OPPOSITE SIDE!)\n",
    "camera_2_pos = np.array([-0.3, -0.95, 0.25])\n",
    "\n",
    "# Camera 3: Left side, medium height (looking from -x direction)\n",
    "camera_3_pos = np.array([-0.45, -0.5, 0.4])\n",
    "\n",
    "X_WorldToCamera_1 = make_camera_transform(camera_1_pos, workspace_center)\n",
    "X_WorldToCamera_2 = make_camera_transform(camera_2_pos, workspace_center)\n",
    "X_WorldToCamera_3 = make_camera_transform(camera_3_pos, workspace_center)\n",
    "\n",
    "# Create 3 sets of cameras\n",
    "color_camera_1, depth_camera_1 = camera_config.MakeCameras()\n",
    "color_camera_2, depth_camera_2 = camera_config.MakeCameras()\n",
    "color_camera_3, depth_camera_3 = camera_config.MakeCameras()\n",
    "\n",
    "# Add 3 RgbdSensors to diagram\n",
    "rgbd_sensor_1 = builder.AddSystem(RgbdSensor(\n",
    "    parent_id=scene_graph.world_frame_id(),\n",
    "    X_PB=X_WorldToCamera_1,\n",
    "    color_camera=color_camera_1,\n",
    "    depth_camera=depth_camera_1\n",
    "))\n",
    "\n",
    "rgbd_sensor_2 = builder.AddSystem(RgbdSensor(\n",
    "    parent_id=scene_graph.world_frame_id(),\n",
    "    X_PB=X_WorldToCamera_2,\n",
    "    color_camera=color_camera_2,\n",
    "    depth_camera=depth_camera_2\n",
    "))\n",
    "\n",
    "rgbd_sensor_3 = builder.AddSystem(RgbdSensor(\n",
    "    parent_id=scene_graph.world_frame_id(),\n",
    "    X_PB=X_WorldToCamera_3,\n",
    "    color_camera=color_camera_3,\n",
    "    depth_camera=depth_camera_3\n",
    "))\n",
    "\n",
    "# Connect all 3 sensors to scene graph\n",
    "builder.Connect(\n",
    "    station.GetOutputPort(\"query_object\"),\n",
    "    rgbd_sensor_1.query_object_input_port()\n",
    ")\n",
    "builder.Connect(\n",
    "    station.GetOutputPort(\"query_object\"),\n",
    "    rgbd_sensor_2.query_object_input_port()\n",
    ")\n",
    "builder.Connect(\n",
    "    station.GetOutputPort(\"query_object\"),\n",
    "    rgbd_sensor_3.query_object_input_port()\n",
    ")\n",
    "\n",
    "# Build complete diagram\n",
    "diagram = builder.Build()\n",
    "\n",
    "# Initialize simulation\n",
    "simulator = Simulator(diagram)\n",
    "simulator.set_target_realtime_rate(1.0)\n",
    "context = simulator.get_mutable_context()\n",
    "\n",
    "plant = station.GetSubsystemByName(\"plant\")\n",
    "plant_context = plant.GetMyContextFromRoot(context)\n",
    "\n",
    "# Home position (more vertical, closer to grasp pose)\n",
    "q_home = np.array([0, 0.1, 0, -1.8, 0, 1.6, 0])\n",
    "plant.SetPositions(plant_context, plant.GetModelInstanceByName(\"iiwa\"), q_home)\n",
    "\n",
    "simulator.AdvanceTo(0.1)\n",
    "\n",
    "# Visualize all 3 cameras in meshcat\n",
    "from pydrake.geometry import Cylinder\n",
    "\n",
    "camera_colors = [\n",
    "    Rgba(0.2, 0.2, 0.8, 0.8),  # Blue for camera 1\n",
    "    Rgba(0.2, 0.8, 0.2, 0.8),  # Green for camera 2\n",
    "    Rgba(0.8, 0.2, 0.2, 0.8)   # Red for camera 3\n",
    "]\n",
    "\n",
    "camera_transforms = [X_WorldToCamera_1, X_WorldToCamera_2, X_WorldToCamera_3]\n",
    "camera_positions = [camera_1_pos, camera_2_pos, camera_3_pos]\n",
    "\n",
    "for i, (X_cam, pos, color) in enumerate(zip(camera_transforms, camera_positions, camera_colors), 1):\n",
    "    meshcat.SetObject(f\"camera{i}/body\", Box(0.05, 0.05, 0.08), color)\n",
    "    meshcat.SetTransform(f\"camera{i}/body\", X_cam)\n",
    "    \n",
    "    lens_color = Rgba(color.r() * 0.5, color.g() * 0.5, color.b() * 0.5, 0.9)\n",
    "    meshcat.SetObject(f\"camera{i}/lens\", Cylinder(0.02, 0.03), lens_color)\n",
    "    meshcat.SetTransform(f\"camera{i}/lens\", X_cam @ RigidTransform([0, 0, 0.05]))\n",
    "\n",
    "# Save camera info and sensors for perception\n",
    "camera_info_1 = color_camera_1.core().intrinsics()\n",
    "camera_info_2 = color_camera_2.core().intrinsics()\n",
    "camera_info_3 = color_camera_3.core().intrinsics()\n",
    "\n",
    "# Store for later use\n",
    "camera_sensors = [rgbd_sensor_1, rgbd_sensor_2, rgbd_sensor_3]\n",
    "camera_infos = [camera_info_1, camera_info_2, camera_info_3]\n",
    "camera_transforms = [X_WorldToCamera_1, X_WorldToCamera_2, X_WorldToCamera_3]\n",
    "\n",
    "# Save ball positions for later\n",
    "ball_radius = 0.05\n",
    "blue_positions = [blue_pos]\n",
    "\n",
    "print(\"✓ Scene built with robot, gripper, 3 cameras, AND BIN WITH COLLISION\")\n",
    "print(f\"  Resolution: {width}x{height} per camera\")\n",
    "print(f\"  Renderer: {renderer_name}\")\n",
    "print(f\"  Red ball at: {red_pos}\")\n",
    "print(f\"  Blue ball at: {blue_pos}\")\n",
    "print(f\"\\n  Camera positions SPREAD AROUND workspace (NOT coplanar!):\")\n",
    "print(f\"  Camera 1 (blue):  {camera_1_pos} - Front-right, HIGH\")\n",
    "print(f\"  Camera 2 (green): {camera_2_pos} - Back-left (OPPOSITE SIDE!), LOW\")\n",
    "print(f\"  Camera 3 (red):   {camera_3_pos} - Left side, MEDIUM\")\n",
    "print(f\"\\n✓ Cameras now view from ~120° apart for better triangulation!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Bin added to scene\n",
      "  (Balls are in scene graph from cell 3)\n"
     ]
    }
   ],
   "source": [
    "# Add bin visualization to Meshcat (balls are now in scene graph, no need to visualize separately)\n",
    "\n",
    "bin_x, bin_y = 0, -0.6\n",
    "bin_w, bin_h, bin_d = 0.25, 0.25, 0.08\n",
    "wall_thickness = 0.01\n",
    "\n",
    "# Bin walls (visual only)\n",
    "bin_color = Rgba(0.6, 0.4, 0.3, 0.6)\n",
    "meshcat.SetObject(\"bin/floor\", Box(bin_w, bin_h, wall_thickness), bin_color)\n",
    "meshcat.SetTransform(\"bin/floor\", RigidTransform([bin_x, bin_y, 0.0]))\n",
    "\n",
    "meshcat.SetObject(\"bin/front\", Box(bin_w, wall_thickness, bin_d), bin_color)\n",
    "meshcat.SetTransform(\"bin/front\", RigidTransform([bin_x, bin_y - bin_h/2, bin_d/2]))\n",
    "\n",
    "meshcat.SetObject(\"bin/back\", Box(bin_w, wall_thickness, bin_d), bin_color)\n",
    "meshcat.SetTransform(\"bin/back\", RigidTransform([bin_x, bin_y + bin_h/2, bin_d/2]))\n",
    "\n",
    "meshcat.SetObject(\"bin/left\", Box(wall_thickness, bin_h, bin_d), bin_color)\n",
    "meshcat.SetTransform(\"bin/left\", RigidTransform([bin_x - bin_w/2, bin_y, bin_d/2]))\n",
    "\n",
    "meshcat.SetObject(\"bin/right\", Box(wall_thickness, bin_h, bin_d), bin_color)\n",
    "meshcat.SetTransform(\"bin/right\", RigidTransform([bin_x + bin_w/2, bin_y, bin_d/2]))\n",
    "\n",
    "print(f\"✓ Bin added to scene\")\n",
    "print(f\"  (Balls are in scene graph from cell 3)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== MULTI-CAMERA PERCEPTION PIPELINE ===\n",
      "\n",
      "--- Camera 1 ---\n",
      "  Depth range: [0.46, 0.70]m\n",
      "  Depth pixels: 307200\n",
      "  Generated 71276 points\n",
      "  ✓ Transformed to world frame\n",
      "\n",
      "--- Camera 2 ---\n",
      "  Depth range: [0.19, 0.49]m\n",
      "  Depth pixels: 307200\n",
      "  Generated 169439 points\n",
      "  ✓ Transformed to world frame\n",
      "\n",
      "--- Camera 3 ---\n",
      "  Depth range: [0.36, 0.61]m\n",
      "  Depth pixels: 307200\n",
      "  Generated 103365 points\n",
      "  ✓ Transformed to world frame\n",
      "\n",
      "============================================================\n",
      "✓ MERGED POINT CLOUDS FROM 3 CAMERAS\n",
      "  Total points: 344080\n",
      "  Camera 1: 71276 points\n",
      "  Camera 2: 169439 points\n",
      "  Camera 3: 103365 points\n",
      "============================================================\n",
      "\n",
      "--- Color Segmentation ---\n",
      "Found 206491 red points\n",
      "  (Thresholds: red>0.4, green/blue<0.5)\n",
      "\n",
      "--- Detection Results ---\n",
      "Detected position: [ 0.04536715 -0.57600364  0.04280791]\n",
      "Ground truth:      [ 0.05 -0.55  0.04]\n",
      "Error: 26.6mm\n",
      "Improvement vs single camera: 12.2mm better!\n",
      "\n",
      "============================================================\n",
      "✓ MULTI-CAMERA DETECTION SUCCESSFUL!\n",
      "============================================================\n",
      "✓ Captured from 3 cameras\n",
      "✓ Merged 344080 total points\n",
      "✓ Detected red ball with 26.6mm error\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# PERCEPTION: Multi-camera capture and point cloud fusion\n",
    "\n",
    "print(\"=== MULTI-CAMERA PERCEPTION PIPELINE ===\\n\")\n",
    "\n",
    "# Lists to store point clouds from all cameras\n",
    "all_points_world = []\n",
    "all_colors = []\n",
    "\n",
    "# Process each camera\n",
    "for cam_idx, (sensor, cam_info, X_cam) in enumerate(zip(camera_sensors, camera_infos, camera_transforms), 1):\n",
    "    print(f\"--- Camera {cam_idx} ---\")\n",
    "    \n",
    "    # Get images from this sensor\n",
    "    sensor_context = sensor.GetMyContextFromRoot(context)\n",
    "    \n",
    "    color_image = sensor.color_image_output_port().Eval(sensor_context)\n",
    "    rgb_img = color_image.data[:, :, :3].astype(np.uint8)\n",
    "    \n",
    "    depth_image = sensor.depth_image_32F_output_port().Eval(sensor_context)\n",
    "    depth_img = depth_image.data.squeeze().astype(np.float32)\n",
    "    \n",
    "    # Report depth statistics\n",
    "    if np.any(depth_img > 0):\n",
    "        depth_valid = depth_img[(depth_img > 0) & (depth_img < 10)]\n",
    "        if len(depth_valid) > 0:\n",
    "            depth_min = depth_valid.min()\n",
    "            depth_max = depth_valid.max()\n",
    "            print(f\"  Depth range: [{depth_min:.2f}, {depth_max:.2f}]m\")\n",
    "            print(f\"  Depth pixels: {np.sum(depth_img > 0)}\")\n",
    "    \n",
    "    # Convert to point cloud in camera frame\n",
    "    points_camera, colors = depth_image_to_point_cloud(depth_img, rgb_img, cam_info)\n",
    "    print(f\"  Generated {len(points_camera)} points\")\n",
    "    \n",
    "    # Transform to world frame\n",
    "    points_world = transform_points_to_world(points_camera, X_cam)\n",
    "    \n",
    "    # Accumulate\n",
    "    all_points_world.append(points_world)\n",
    "    all_colors.append(colors)\n",
    "    print(f\"  ✓ Transformed to world frame\\n\")\n",
    "\n",
    "# Merge all point clouds\n",
    "merged_points = np.vstack(all_points_world)\n",
    "merged_colors = np.vstack(all_colors)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(f\"✓ MERGED POINT CLOUDS FROM {len(camera_sensors)} CAMERAS\")\n",
    "print(f\"  Total points: {len(merged_points)}\")\n",
    "print(f\"  Camera 1: {len(all_points_world[0])} points\")\n",
    "print(f\"  Camera 2: {len(all_points_world[1])} points\")\n",
    "print(f\"  Camera 3: {len(all_points_world[2])} points\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "# Color segmentation on merged point cloud\n",
    "print(\"--- Color Segmentation ---\")\n",
    "red_points = segment_red_color(merged_points, merged_colors, red_min=0.4, other_max=0.5)\n",
    "print(f\"Found {len(red_points)} red points\")\n",
    "print(f\"  (Thresholds: red>0.4, green/blue<0.5)\\n\")\n",
    "\n",
    "# Compute ball center from merged data\n",
    "detected_red_pos = compute_ball_center(red_points)\n",
    "\n",
    "if detected_red_pos is not None:\n",
    "    error = np.linalg.norm(detected_red_pos - red_pos)\n",
    "    print(\"--- Detection Results ---\")\n",
    "    print(f\"Detected position: {detected_red_pos}\")\n",
    "    print(f\"Ground truth:      {red_pos}\")\n",
    "    print(f\"Error: {error*1000:.1f}mm\")\n",
    "    print(f\"Improvement vs single camera: {38.8 - error*1000:.1f}mm better!\\n\")\n",
    "    \n",
    "    # Visualize detection\n",
    "    meshcat.SetObject(\"perception/detected\", Sphere(0.055), Rgba(1.0, 0.5, 0.0, 0.6))\n",
    "    meshcat.SetTransform(\"perception/detected\", RigidTransform(detected_red_pos))\n",
    "    \n",
    "    # Visualize red point cloud (downsample for performance)\n",
    "    downsample_rate = max(1, len(red_points)//100)\n",
    "    for i in range(0, len(red_points), downsample_rate):\n",
    "        meshcat.SetObject(f\"perception/red_pt_{i}\", Sphere(0.003), Rgba(1, 0, 0, 0.8))\n",
    "        meshcat.SetTransform(f\"perception/red_pt_{i}\", RigidTransform(red_points[i]))\n",
    "    \n",
    "    # Visualize contributions from each camera (different colors)\n",
    "    cam_colors_viz = [\n",
    "        Rgba(0.3, 0.3, 1.0, 0.5),  # Blue\n",
    "        Rgba(0.3, 1.0, 0.3, 0.5),  # Green\n",
    "        Rgba(1.0, 0.3, 0.3, 0.5)   # Red\n",
    "    ]\n",
    "    \n",
    "    for cam_idx, (points, color) in enumerate(zip(all_points_world, cam_colors_viz)):\n",
    "        # Segment red from this camera's points\n",
    "        colors_cam = all_colors[cam_idx]\n",
    "        red_mask = (\n",
    "            (colors_cam[:, 0] > 0.4) &\n",
    "            (colors_cam[:, 1] < 0.5) &\n",
    "            (colors_cam[:, 2] < 0.5)\n",
    "        )\n",
    "        red_points_cam = points[red_mask]\n",
    "        \n",
    "        # Show a few points from each camera\n",
    "        downsample = max(1, len(red_points_cam)//20)\n",
    "        for i in range(0, len(red_points_cam), downsample):\n",
    "            meshcat.SetObject(\n",
    "                f\"perception/cam{cam_idx+1}_pt_{i}\", \n",
    "                Sphere(0.004), \n",
    "                color\n",
    "            )\n",
    "            meshcat.SetTransform(\n",
    "                f\"perception/cam{cam_idx+1}_pt_{i}\", \n",
    "                RigidTransform(red_points_cam[i])\n",
    "            )\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"✓ MULTI-CAMERA DETECTION SUCCESSFUL!\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"✓ Captured from 3 cameras\")\n",
    "    print(f\"✓ Merged {len(merged_points)} total points\")\n",
    "    print(f\"✓ Detected red ball with {error*1000:.1f}mm error\")\n",
    "    print(\"=\"*60)\n",
    "else:\n",
    "    print(\"✗ No red ball detected\")\n",
    "    print(\"  Try adjusting color thresholds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== MANIPULATION: Pick Detected Ball ===\n",
      "\n",
      "Target ball position: [ 0.04536715 -0.57600364  0.04280791]\n",
      "\n",
      "WSG gripper has 0 position(s)\n",
      "Step 0: Moving to HOME position...\n",
      "  ✓ At home, gripper open\n",
      "\n",
      "Planning waypoints (relaxed constraints for perception):\n",
      "  ✓ Pre-grasp at [ 0.04536715 -0.57600364  0.19280791]\n",
      "  ✓ Grasp at [ 0.04536715 -0.57600364  0.10280791]\n",
      "  ✓ Lift at [ 0.04536715 -0.57600364  0.19280791]\n",
      "\n",
      "✓ Planned 3/3 waypoints\n",
      "\n",
      "=== Executing motion sequence WITH GRIPPER ===\n",
      "\n",
      "  → Moving to Pre-grasp...\n",
      "    ✓ Pre-grasp (gripper: OPEN)\n",
      "  → Moving to Grasp...\n",
      "    ✓ Grasp (gripper: CLOSED)\n",
      "  → Moving to Lift...\n",
      "    ✓ Lift (gripper: OPEN)\n",
      "\n",
      "============================================================\n",
      "SUCCESS! PERCEPTION + MANIPULATION + GRASPING COMPLETE\n",
      "============================================================\n",
      "✓ Camera detected red ball via perception\n",
      "✓ Executed 3 waypoint motion with gripper control\n",
      "✓ Angle normalization applied - no more 360 spins!\n",
      "  Total duration: 4.1s\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# MANIPULATION: Pick the detected red ball WITH GRIPPER CONTROL\n",
    "\n",
    "if detected_red_pos is None:\n",
    "    print(\"ERROR: No ball detected, cannot proceed with manipulation\")\n",
    "else:\n",
    "    print(\"=== MANIPULATION: Pick Detected Ball ===\\n\")\n",
    "    \n",
    "    # Use perception-detected position\n",
    "    target_pos = detected_red_pos\n",
    "    print(f\"Target ball position: {target_pos}\\n\")\n",
    "    \n",
    "    # Get WSG gripper info\n",
    "    wsg = plant.GetModelInstanceByName(\"wsg\")\n",
    "    num_wsg_positions = plant.num_positions(wsg)\n",
    "    print(f\"WSG gripper has {num_wsg_positions} position(s)\")\n",
    "    \n",
    "    # Move to home first with gripper OPEN\n",
    "    print(\"Step 0: Moving to HOME position...\")\n",
    "    plant.SetPositions(plant_context, plant.GetModelInstanceByName(\"iiwa\"), q_home)\n",
    "    \n",
    "    # Open gripper - WSG uses single value for both fingers\n",
    "    if num_wsg_positions == 2:\n",
    "        plant.SetPositions(plant_context, wsg, [-0.05, 0.05])  # Open (left=-0.05, right=0.05)\n",
    "    else:\n",
    "        plant.SetPositions(plant_context, wsg, np.zeros(num_wsg_positions))\n",
    "    \n",
    "    diagram.ForcedPublish(context)\n",
    "    time.sleep(0.3)\n",
    "    print(\"  ✓ At home, gripper open\\n\")\n",
    "    \n",
    "    # Compute grasp pose\n",
    "    X_WG_grasp = compute_sphere_grasp(target_pos, ball_radius)\n",
    "    \n",
    "    # Plan waypoints with RELAXED constraints for perception uncertainty\n",
    "    print(\"Planning waypoints (relaxed constraints for perception):\")\n",
    "    \n",
    "    # Waypoint 1: Pre-grasp (15cm above ball)\n",
    "    pre_grasp_pos = target_pos + np.array([0, 0, 0.15])\n",
    "    success_pre, q_pregrasp = solve_ik_position_priority(\n",
    "        plant, plant_context, pre_grasp_pos, \n",
    "        orientation_target=X_WG_grasp.rotation(), pos_tol=0.01\n",
    "    )\n",
    "    \n",
    "    # Waypoint 2: Grasp (at ball)\n",
    "    grasp_pos = X_WG_grasp.translation()\n",
    "    success_grasp, q_grasp = solve_ik_position_priority(\n",
    "        plant, plant_context, grasp_pos, \n",
    "        orientation_target=X_WG_grasp.rotation(), pos_tol=0.01\n",
    "    )\n",
    "    \n",
    "    # Waypoint 3: Lift (15cm above ball) - relaxed orientation\n",
    "    lift_pos = target_pos + np.array([0, 0, 0.15])\n",
    "    success_lift, q_lift = solve_ik_position_priority(\n",
    "        plant, plant_context, lift_pos,\n",
    "        orientation_target=None,  # No orientation constraint\n",
    "        pos_tol=0.02\n",
    "    )\n",
    "    \n",
    "    # Waypoint 4: Higher lift if waypoint 3 failed\n",
    "    if not success_lift:\n",
    "        lift_pos = target_pos + np.array([0, 0, 0.12])\n",
    "        success_lift, q_lift = solve_ik_position_priority(\n",
    "            plant, plant_context, lift_pos,\n",
    "            orientation_target=None,\n",
    "            pos_tol=0.02\n",
    "        )\n",
    "    \n",
    "    # Build waypoint list\n",
    "    waypoints = []\n",
    "    waypoint_names = []\n",
    "    successes = [success_pre, success_grasp, success_lift]\n",
    "    names = [\"Pre-grasp\", \"Grasp\", \"Lift\"]\n",
    "    qs = [q_pregrasp, q_grasp, q_lift]\n",
    "    positions = [pre_grasp_pos, grasp_pos, lift_pos]\n",
    "    \n",
    "    for success, name, q, pos in zip(successes, names, qs, positions):\n",
    "        status = \"✓\" if success else \"✗\"\n",
    "        print(f\"  {status} {name} at {pos}\")\n",
    "        if success:\n",
    "            waypoints.append(q)\n",
    "            waypoint_names.append(name)\n",
    "    \n",
    "    print(f\"\\n✓ Planned {len(waypoints)}/{len(names)} waypoints\\n\")\n",
    "    \n",
    "    # Visualize waypoints\n",
    "    if success_pre:\n",
    "        meshcat.SetObject(\"waypoints/pregrasp\", Sphere(0.02), Rgba(1, 1, 0, 0.6))\n",
    "        meshcat.SetTransform(\"waypoints/pregrasp\", RigidTransform(pre_grasp_pos))\n",
    "    if success_grasp:\n",
    "        meshcat.SetObject(\"waypoints/grasp\", Sphere(0.02), Rgba(0, 1, 0, 0.8))\n",
    "        meshcat.SetTransform(\"waypoints/grasp\", RigidTransform(grasp_pos))\n",
    "    if success_lift:\n",
    "        meshcat.SetObject(\"waypoints/lift\", Sphere(0.02), Rgba(0, 1, 1, 0.6))\n",
    "        meshcat.SetTransform(\"waypoints/lift\", RigidTransform(lift_pos))\n",
    "    \n",
    "    # Execute motion with gripper control (accept 2+ waypoints)\n",
    "    if len(waypoints) >= 2:\n",
    "        print(\"=== Executing motion sequence WITH GRIPPER ===\\n\")\n",
    "        \n",
    "        meshcat.StartRecording()\n",
    "        \n",
    "        all_waypoints = [q_home] + waypoints\n",
    "        all_names = [\"Home\"] + waypoint_names\n",
    "        \n",
    "        sim_time = 0.0\n",
    "        dt = 0.03\n",
    "        \n",
    "        # Gripper positions: open for pre-grasp, close for grasp/lift\n",
    "        for i in range(len(all_waypoints) - 1):\n",
    "            q_start = all_waypoints[i]\n",
    "            q_end = normalize_joint_angles(q_start, all_waypoints[i + 1])  # Prevent 360 spins!\n",
    "            name = all_names[i + 1]\n",
    "            \n",
    "            # Determine gripper state\n",
    "            if name == \"Grasp\":\n",
    "                gripper_open = False\n",
    "            else:\n",
    "                gripper_open = True\n",
    "            \n",
    "            print(f\"  → Moving to {name}...\")\n",
    "            \n",
    "            num_steps = 35\n",
    "            for step in range(num_steps + 1):\n",
    "                alpha = step / num_steps\n",
    "                q_interp = (1 - alpha) * q_start + alpha * q_end\n",
    "                \n",
    "                # Set robot position\n",
    "                plant.SetPositions(plant_context, plant.GetModelInstanceByName(\"iiwa\"), q_interp)\n",
    "                \n",
    "                # Set gripper position (simplified - just open or closed)\n",
    "                if num_wsg_positions == 2:\n",
    "                    if gripper_open:\n",
    "                        plant.SetPositions(plant_context, wsg, [-0.05, 0.05])  # Open\n",
    "                    else:\n",
    "                        plant.SetPositions(plant_context, wsg, [-0.01, 0.01])  # Closed\n",
    "                \n",
    "                context.SetTime(sim_time)\n",
    "                diagram.ForcedPublish(context)\n",
    "                \n",
    "                time.sleep(dt)\n",
    "                sim_time += dt\n",
    "            \n",
    "            grip_status = \"OPEN\" if gripper_open else \"CLOSED\"\n",
    "            print(f\"    ✓ {name} (gripper: {grip_status})\")\n",
    "            time.sleep(0.3)\n",
    "            sim_time += 0.3\n",
    "        \n",
    "        meshcat.StopRecording()\n",
    "        meshcat.PublishRecording()\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"SUCCESS! PERCEPTION + MANIPULATION + GRASPING COMPLETE\")\n",
    "        print(\"=\"*60)\n",
    "        print(f\"✓ Camera detected red ball via perception\")\n",
    "        print(f\"✓ Executed {len(waypoints)} waypoint motion with gripper control\")\n",
    "        print(f\"✓ Angle normalization applied - no more 360 spins!\")\n",
    "        print(f\"  Total duration: {sim_time:.1f}s\")\n",
    "        print(\"=\"*60)\n",
    "    else:\n",
    "        print(\"✗ Too few waypoints succeeded\")\n",
    "        print(f\"  Detected position: {target_pos}\")\n",
    "        print(f\"  Try adjusting detection or IK tolerances\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
