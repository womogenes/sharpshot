{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cell-0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports loaded\n"
     ]
    }
   ],
   "source": [
    "# FINAL NOTEBOOK: Perception + Pick + Throw Pipeline\n",
    "# Combines pick_colored_ball_camera.ipynb and arc_trajectory_planning.ipynb\n",
    "#\n",
    "# Pipeline:\n",
    "# 1. Setup scene with robot, table, red/blue balls, 4 cameras\n",
    "# 2. Multi-camera perception to detect red ball\n",
    "# 3. Pick trajectory to grasp detected ball\n",
    "# 4. Throw trajectory to launch ball at target\n",
    "\n",
    "from pydrake.all import *\n",
    "from manipulation.station import LoadScenario, MakeHardwareStation\n",
    "from manipulation.meshcat_utils import AddMeshcatTriad\n",
    "from pydrake.geometry import Rgba, Cylinder\n",
    "from pydrake.systems.sensors import RgbdSensor, CameraConfig\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import tempfile\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(str(Path.cwd()))\n",
    "from throw_helpers import create_q_knots, joint_angles_to_pose\n",
    "\n",
    "print(\"Imports loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cell-1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:drake:Meshcat listening for connections at http://localhost:7001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meshcat: http://localhost:7001\n"
     ]
    }
   ],
   "source": [
    "# Start meshcat\n",
    "meshcat = StartMeshcat()\n",
    "print(f\"Meshcat: {meshcat.web_url()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cell-2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perception functions defined\n"
     ]
    }
   ],
   "source": [
    "# Perception helper functions\n",
    "\n",
    "def depth_image_to_point_cloud(depth_image, rgb_image, camera_info):\n",
    "    \"\"\"Convert depth image to colored point cloud in camera frame\"\"\"\n",
    "    height, width = depth_image.shape\n",
    "    fx = camera_info.focal_x()\n",
    "    fy = camera_info.focal_y()\n",
    "    cx = camera_info.center_x()\n",
    "    cy = camera_info.center_y()\n",
    "    \n",
    "    u = np.arange(width)\n",
    "    v = np.arange(height)\n",
    "    u_grid, v_grid = np.meshgrid(u, v)\n",
    "    \n",
    "    valid = (depth_image > 0.01) & (depth_image < 5.0)\n",
    "    \n",
    "    u_valid = u_grid[valid]\n",
    "    v_valid = v_grid[valid]\n",
    "    z_valid = depth_image[valid]\n",
    "    \n",
    "    x = (u_valid - cx) * z_valid / fx\n",
    "    y = (v_valid - cy) * z_valid / fy\n",
    "    z = z_valid\n",
    "    \n",
    "    points = np.column_stack([x, y, z])\n",
    "    colors = rgb_image[valid].astype(float) / 255.0\n",
    "    \n",
    "    return points, colors\n",
    "\n",
    "\n",
    "def transform_points_to_world(points, X_CameraToWorld):\n",
    "    \"\"\"Transform points from camera frame to world frame\"\"\"\n",
    "    points_world = []\n",
    "    for pt in points:\n",
    "        pt_world = X_CameraToWorld @ pt\n",
    "        points_world.append(pt_world)\n",
    "    return np.array(points_world)\n",
    "\n",
    "\n",
    "def make_camera_transform(camera_pos, look_at_pos):\n",
    "    \"\"\"Create camera transform that looks from camera_pos to look_at_pos\"\"\"\n",
    "    forward = look_at_pos - camera_pos\n",
    "    forward = forward / np.linalg.norm(forward)\n",
    "    world_up = np.array([0, 0, 1])\n",
    "    right = np.cross(forward, world_up)\n",
    "    right = right / np.linalg.norm(right)\n",
    "    down = np.cross(forward, right)\n",
    "    R_WorldToCamera = RotationMatrix(np.column_stack([right, down, forward]))\n",
    "    return RigidTransform(R_WorldToCamera, camera_pos)\n",
    "\n",
    "\n",
    "print(\"Perception functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cell-3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:drake:PackageMap: Downloading https://github.com/RobotLocomotion/models/archive/7b92aacbe021861ec9bbbb82d8ab9a19ded970ff.tar.gz\n",
      "WARNING:drake:Drake materials have been assigned to a glTF file. glTF defines its own materials, so post hoc materials will be ignored and should be removed from the model specification. glTF file: '/root/.cache/drake/package_map/719c542a6323d5a8cc74fe6da84f305aebc6d7810b84cb94023d80f78e06586b-6e8a5cbbb49ceed5e2ae3a392577ca12bd01fd5983dc56151cb5fa7d55d27ed8/wsg_50_description/meshes/wsg_body.gltf'\n",
      "WARNING:drake:Drake materials have been assigned to a glTF file. glTF defines its own materials, so post hoc materials will be ignored and should be removed from the model specification. glTF file: '/root/.cache/drake/package_map/719c542a6323d5a8cc74fe6da84f305aebc6d7810b84cb94023d80f78e06586b-6e8a5cbbb49ceed5e2ae3a392577ca12bd01fd5983dc56151cb5fa7d55d27ed8/wsg_50_description/meshes/finger_with_tip.gltf'\n",
      "WARNING:drake:Drake materials have been assigned to a glTF file. glTF defines its own materials, so post hoc materials will be ignored and should be removed from the model specification. glTF file: '/root/.cache/drake/package_map/719c542a6323d5a8cc74fe6da84f305aebc6d7810b84cb94023d80f78e06586b-6e8a5cbbb49ceed5e2ae3a392577ca12bd01fd5983dc56151cb5fa7d55d27ed8/wsg_50_description/meshes/finger_with_tip.gltf'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial gripper pose: [ 3.70783219e-04 -4.65616808e-01  6.79321579e-01]\n",
      "\n",
      "Scene setup complete:\n",
      "  Red ball: [ 0.   -0.5   0.05]\n",
      "  Blue ball: [-0.15 -0.55  0.05]\n",
      "  4 cameras positioned around workspace\n"
     ]
    }
   ],
   "source": [
    "# Scene setup: Robot + Table + 2 Balls + 4 Cameras\n",
    "\n",
    "# Create temporary SDF files for balls\n",
    "temp_dir = tempfile.mkdtemp()\n",
    "\n",
    "red_ball_sdf = \"\"\"<?xml version=\"1.0\"?>\n",
    "<sdf version=\"1.7\">\n",
    "  <model name=\"red_ball\">\n",
    "    <link name=\"ball\">\n",
    "      <inertial>\n",
    "        <mass>0.1</mass>\n",
    "        <inertia>\n",
    "          <ixx>0.0001</ixx><ixy>0</ixy><ixz>0</ixz>\n",
    "          <iyy>0.0001</iyy><iyz>0</iyz><izz>0.0001</izz>\n",
    "        </inertia>\n",
    "      </inertial>\n",
    "      <visual name=\"visual\">\n",
    "        <geometry><sphere><radius>0.05</radius></sphere></geometry>\n",
    "        <material><diffuse>0.9 0.1 0.1 1.0</diffuse></material>\n",
    "      </visual>\n",
    "      <collision name=\"collision\">\n",
    "        <geometry><sphere><radius>0.05</radius></sphere></geometry>\n",
    "      </collision>\n",
    "    </link>\n",
    "  </model>\n",
    "</sdf>\n",
    "\"\"\"\n",
    "\n",
    "blue_ball_sdf = \"\"\"<?xml version=\"1.0\"?>\n",
    "<sdf version=\"1.7\">\n",
    "  <model name=\"blue_ball\">\n",
    "    <link name=\"ball\">\n",
    "      <inertial>\n",
    "        <mass>0.1</mass>\n",
    "        <inertia>\n",
    "          <ixx>0.0001</ixx><ixy>0</ixy><ixz>0</ixz>\n",
    "          <iyy>0.0001</iyy><iyz>0</iyz><izz>0.0001</izz>\n",
    "        </inertia>\n",
    "      </inertial>\n",
    "      <visual name=\"visual\">\n",
    "        <geometry><sphere><radius>0.05</radius></sphere></geometry>\n",
    "        <material><diffuse>0.2 0.4 0.9 1.0</diffuse></material>\n",
    "      </visual>\n",
    "      <collision name=\"collision\">\n",
    "        <geometry><sphere><radius>0.05</radius></sphere></geometry>\n",
    "      </collision>\n",
    "    </link>\n",
    "  </model>\n",
    "</sdf>\n",
    "\"\"\"\n",
    "\n",
    "red_ball_path = os.path.join(temp_dir, \"red_ball.sdf\")\n",
    "blue_ball_path = os.path.join(temp_dir, \"blue_ball.sdf\")\n",
    "\n",
    "with open(red_ball_path, 'w') as f:\n",
    "    f.write(red_ball_sdf)\n",
    "with open(blue_ball_path, 'w') as f:\n",
    "    f.write(blue_ball_sdf)\n",
    "\n",
    "# Ball positions on table\n",
    "ball_radius = 0.05\n",
    "red_pos = np.array([0.0, -0.5, ball_radius])\n",
    "blue_pos = np.array([-0.15, -0.55, ball_radius])\n",
    "\n",
    "# Table path\n",
    "abs_table_sdf_path = f\"{Path.cwd()}/assets/table.sdf\"\n",
    "\n",
    "# Scenario YAML with free-body balls\n",
    "scenario_yaml = f\"\"\"\n",
    "directives:\n",
    "- add_model:\n",
    "    name: iiwa\n",
    "    file: package://drake_models/iiwa_description/sdf/iiwa7_no_collision.sdf\n",
    "    default_joint_positions:\n",
    "      iiwa_joint_1: [-1.57]\n",
    "      iiwa_joint_2: [0.1]\n",
    "      iiwa_joint_3: [0]\n",
    "      iiwa_joint_4: [-1.2]\n",
    "      iiwa_joint_5: [0]\n",
    "      iiwa_joint_6: [1.6]\n",
    "      iiwa_joint_7: [0]\n",
    "- add_weld:\n",
    "    parent: world\n",
    "    child: iiwa::iiwa_link_0\n",
    "- add_model:\n",
    "    name: wsg\n",
    "    file: package://manipulation/hydro/schunk_wsg_50_with_tip.sdf\n",
    "- add_weld:\n",
    "    parent: iiwa::iiwa_link_7\n",
    "    child: wsg::body\n",
    "    X_PC:\n",
    "      translation: [0, 0, 0.09]\n",
    "      rotation: !Rpy {{ deg: [90, 0, 90] }}\n",
    "- add_model:\n",
    "    name: table\n",
    "    file: file://{abs_table_sdf_path}\n",
    "- add_weld:\n",
    "    parent: world\n",
    "    child: table::table_link\n",
    "    X_PC:\n",
    "      translation: [0.0, 0.0, -0.05]\n",
    "      rotation: !Rpy {{ deg: [0, 0, -90] }}\n",
    "- add_model:\n",
    "    name: red_ball\n",
    "    file: file://{red_ball_path}\n",
    "    default_free_body_pose:\n",
    "      ball:\n",
    "        translation: [{red_pos[0]}, {red_pos[1]}, {red_pos[2]}]\n",
    "- add_model:\n",
    "    name: blue_ball\n",
    "    file: file://{blue_ball_path}\n",
    "    default_free_body_pose:\n",
    "      ball:\n",
    "        translation: [{blue_pos[0]}, {blue_pos[1]}, {blue_pos[2]}]\n",
    "\n",
    "model_drivers:\n",
    "    iiwa: !IiwaDriver\n",
    "      control_mode: position_only\n",
    "      hand_model_name: wsg\n",
    "    wsg: !SchunkWsgDriver {{}}\n",
    "\"\"\"\n",
    "\n",
    "# Build diagram with cameras\n",
    "meshcat.Delete()\n",
    "scenario = LoadScenario(data=scenario_yaml)\n",
    "builder = DiagramBuilder()\n",
    "\n",
    "station = MakeHardwareStation(scenario, meshcat=meshcat)\n",
    "builder.AddSystem(station)\n",
    "\n",
    "plant = station.GetSubsystemByName(\"plant\")\n",
    "scene_graph = station.GetSubsystemByName(\"scene_graph\")\n",
    "\n",
    "# Get initial gripper pose BEFORE building diagram\n",
    "temp_context = station.CreateDefaultContext()\n",
    "temp_plant_context = plant.GetMyContextFromRoot(temp_context)\n",
    "X_WG_initial = plant.EvalBodyPoseInWorld(temp_plant_context, plant.GetBodyByName(\"body\"))\n",
    "print(f\"Initial gripper pose: {X_WG_initial.translation()}\")\n",
    "\n",
    "# Add VTK renderer\n",
    "renderer_name = \"my_renderer\"\n",
    "scene_graph.AddRenderer(renderer_name, MakeRenderEngineVtk(RenderEngineVtkParams()))\n",
    "\n",
    "# Camera config\n",
    "width, height = 640, 480\n",
    "camera_config = CameraConfig()\n",
    "camera_config.width = width\n",
    "camera_config.height = height\n",
    "camera_config.fps = 10.0\n",
    "camera_config.renderer_name = renderer_name\n",
    "\n",
    "# 4 camera positions spread around workspace\n",
    "workspace_center = np.array([0.0, -0.5, 0.05])\n",
    "camera_positions = [\n",
    "    np.array([0.4, -0.15, 0.5]),    # Front-right, HIGH\n",
    "    np.array([-0.35, -0.9, 0.25]),  # Back-left, LOW\n",
    "    np.array([-0.5, -0.4, 0.4]),    # Left side, MEDIUM\n",
    "    np.array([0.5, -0.6, 0.35]),    # Right side\n",
    "]\n",
    "\n",
    "camera_transforms = [make_camera_transform(pos, workspace_center) for pos in camera_positions]\n",
    "camera_sensors = []\n",
    "camera_infos = []\n",
    "\n",
    "for i, X_cam in enumerate(camera_transforms):\n",
    "    color_cam, depth_cam = camera_config.MakeCameras()\n",
    "    sensor = builder.AddSystem(RgbdSensor(\n",
    "        parent_id=scene_graph.world_frame_id(),\n",
    "        X_PB=X_cam,\n",
    "        color_camera=color_cam,\n",
    "        depth_camera=depth_cam\n",
    "    ))\n",
    "    builder.Connect(station.GetOutputPort(\"query_object\"), sensor.query_object_input_port())\n",
    "    camera_sensors.append(sensor)\n",
    "    camera_infos.append(color_cam.core().intrinsics())\n",
    "\n",
    "# Build diagram\n",
    "diagram = builder.Build()\n",
    "context = diagram.CreateDefaultContext()\n",
    "diagram.ForcedPublish(context)\n",
    "\n",
    "# Visualize cameras\n",
    "cam_colors = [\n",
    "    Rgba(0.0, 0.5, 1.0, 0.8),  # Cyan\n",
    "    Rgba(1.0, 0.5, 0.0, 0.8),  # Orange\n",
    "    Rgba(0.8, 0.0, 0.8, 0.8),  # Purple\n",
    "    Rgba(0.0, 1.0, 0.5, 0.8),  # Teal\n",
    "]\n",
    "\n",
    "for i, (X_cam, color) in enumerate(zip(camera_transforms, cam_colors), 1):\n",
    "    meshcat.SetObject(f\"camera{i}/body\", Box(0.05, 0.05, 0.08), color)\n",
    "    meshcat.SetTransform(f\"camera{i}/body\", X_cam)\n",
    "\n",
    "print(f\"\\nScene setup complete:\")\n",
    "print(f\"  Red ball: {red_pos}\")\n",
    "print(f\"  Blue ball: {blue_pos}\")\n",
    "print(f\"  4 cameras positioned around workspace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cell-4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== MULTI-CAMERA PERCEPTION PIPELINE ===\n",
      "\n",
      "--- Camera 1 ---\n",
      "  Generated 266226 points\n",
      "--- Camera 2 ---\n",
      "  Generated 246300 points\n",
      "--- Camera 3 ---\n",
      "  Generated 270377 points\n",
      "--- Camera 4 ---\n",
      "  Generated 270942 points\n",
      "\n",
      "✓ Merged 1053845 points from 4 cameras\n",
      "\n",
      "--- Visualizing Point Clouds (color-coded by camera) ---\n",
      "  Camera 1: plotting 887 points (Cyan)\n",
      "  Camera 2: plotting 821 points (Orange)\n",
      "  Camera 3: plotting 901 points (Purple)\n",
      "  Camera 4: plotting 903 points (Teal)\n",
      "  ✓ Plotted ~3512 points total\n",
      "  Legend: Cyan=Cam1, Orange=Cam2, Purple=Cam3, Teal=Cam4\n",
      "\n",
      "--- Ball Detection ---\n",
      "Points above table (z > 0.02): 83671\n",
      "Reddest 4183 elevated points selected\n",
      "After clustering: 4244 points\n",
      "\n",
      "Detected: [-0.00219639 -0.50580673  0.05      ]\n",
      "Ground truth: [ 0.   -0.5   0.05]\n",
      "Error: 6.2mm\n",
      "\n",
      "============================================================\n",
      "✓ DETECTED RED BALL - Error: 6.2mm\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# PERCEPTION: Multi-camera capture and point cloud fusion (4 CAMERAS)\n",
    "\n",
    "print(\"=== MULTI-CAMERA PERCEPTION PIPELINE ===\\n\")\n",
    "\n",
    "# Lists to store point clouds from all cameras\n",
    "all_points_world = []\n",
    "all_colors = []\n",
    "\n",
    "# Process each camera\n",
    "for cam_idx, (sensor, cam_info, X_cam) in enumerate(zip(camera_sensors, camera_infos, camera_transforms), 1):\n",
    "    print(f\"--- Camera {cam_idx} ---\")\n",
    "    \n",
    "    # Get images from this sensor\n",
    "    sensor_context = sensor.GetMyContextFromRoot(context)\n",
    "    \n",
    "    color_image = sensor.color_image_output_port().Eval(sensor_context)\n",
    "    rgb_img = color_image.data[:, :, :3].astype(np.uint8)\n",
    "    \n",
    "    depth_image = sensor.depth_image_32F_output_port().Eval(sensor_context)\n",
    "    depth_img = depth_image.data.squeeze().astype(np.float32)\n",
    "    \n",
    "    # Convert to point cloud in camera frame\n",
    "    points_camera, colors = depth_image_to_point_cloud(depth_img, rgb_img, cam_info)\n",
    "    print(f\"  Generated {len(points_camera)} points\")\n",
    "    \n",
    "    # Transform to world frame\n",
    "    points_world = transform_points_to_world(points_camera, X_cam)\n",
    "    \n",
    "    all_points_world.append(points_world)\n",
    "    all_colors.append(colors)\n",
    "\n",
    "# Merge all point clouds\n",
    "merged_points = np.vstack(all_points_world)\n",
    "merged_colors = np.vstack(all_colors)\n",
    "\n",
    "print(f\"\\n✓ Merged {len(merged_points)} points from {len(camera_sensors)} cameras\\n\")\n",
    "\n",
    "# VISUALIZE point clouds from each camera with DIFFERENT COLORS\n",
    "print(\"--- Visualizing Point Clouds (color-coded by camera) ---\")\n",
    "cam_viz_colors = [\n",
    "    Rgba(0.0, 0.5, 1.0, 0.9),   # Cyan - Camera 1\n",
    "    Rgba(1.0, 0.5, 0.0, 0.9),   # Orange - Camera 2  \n",
    "    Rgba(0.8, 0.0, 0.8, 0.9),   # Purple - Camera 3\n",
    "    Rgba(0.0, 1.0, 0.5, 0.9),   # Teal - Camera 4\n",
    "]\n",
    "cam_names = ['Cyan', 'Orange', 'Purple', 'Teal']\n",
    "\n",
    "# Downsample for visualization\n",
    "downsample = 300\n",
    "\n",
    "for cam_idx, (points, viz_color) in enumerate(zip(all_points_world, cam_viz_colors)):\n",
    "    print(f\"  Camera {cam_idx+1}: plotting {len(points)//downsample} points ({cam_names[cam_idx]})\")\n",
    "    for i in range(0, len(points), downsample):\n",
    "        meshcat.SetObject(f\"pointcloud/cam{cam_idx+1}/pt_{i}\", Sphere(0.004), viz_color)\n",
    "        meshcat.SetTransform(f\"pointcloud/cam{cam_idx+1}/pt_{i}\", RigidTransform(points[i]))\n",
    "\n",
    "print(f\"  ✓ Plotted ~{len(merged_points)//downsample} points total\")\n",
    "print(f\"  Legend: Cyan=Cam1, Orange=Cam2, Purple=Cam3, Teal=Cam4\\n\")\n",
    "\n",
    "# BALL DETECTION\n",
    "print(\"--- Ball Detection ---\")\n",
    "\n",
    "# Step 1: Find points that are ABOVE the table (z > 0.02)\n",
    "above_table_mask = merged_points[:, 2] > 0.02\n",
    "above_table_points = merged_points[above_table_mask]\n",
    "above_table_colors = merged_colors[above_table_mask]\n",
    "print(f\"Points above table (z > 0.02): {len(above_table_points)}\")\n",
    "\n",
    "# Step 2: Among elevated points, find the reddest ones\n",
    "if len(above_table_points) > 0:\n",
    "    redness = above_table_colors[:, 0] - np.maximum(above_table_colors[:, 1], above_table_colors[:, 2])\n",
    "    \n",
    "    # Explicitly cast to Python int to avoid numpy int64 indexing issues\n",
    "    num_red_points = int(max(100, int(len(above_table_points) * 0.05)))\n",
    "    red_threshold = np.sort(redness)[-num_red_points]\n",
    "    \n",
    "    is_red = redness >= red_threshold\n",
    "    red_points = above_table_points[is_red]\n",
    "    print(f\"Reddest {num_red_points} elevated points selected\")\n",
    "    \n",
    "    # Step 3: Cluster to find ball center\n",
    "    if len(red_points) > 10:\n",
    "        centroid = np.mean(red_points, axis=0)\n",
    "        \n",
    "        for iteration in range(3):\n",
    "            distances = np.linalg.norm(red_points - centroid, axis=1)\n",
    "            inliers = distances < 0.06\n",
    "            if np.sum(inliers) > 10:\n",
    "                centroid = np.mean(red_points[inliers], axis=0)\n",
    "                red_points = red_points[inliers]\n",
    "        \n",
    "        print(f\"After clustering: {len(red_points)} points\")\n",
    "        \n",
    "        detected_red_pos = np.mean(red_points, axis=0)\n",
    "        detected_red_pos[2] = ball_radius\n",
    "        \n",
    "        error = np.linalg.norm(detected_red_pos - red_pos)\n",
    "        print(f\"\\nDetected: {detected_red_pos}\")\n",
    "        print(f\"Ground truth: {red_pos}\")\n",
    "        print(f\"Error: {error*1000:.1f}mm\")\n",
    "        \n",
    "        # Visualize detected ball (bright yellow)\n",
    "        meshcat.SetObject(\"perception/detected\", Sphere(0.055), Rgba(1.0, 1.0, 0.0, 0.6))\n",
    "        meshcat.SetTransform(\"perception/detected\", RigidTransform(detected_red_pos))\n",
    "        \n",
    "        # Visualize clustered red points (bright green for visibility)\n",
    "        step = int(max(1, len(red_points) // 30))\n",
    "        for i in range(0, len(red_points), step):\n",
    "            meshcat.SetObject(f\"perception/red_pt_{i}\", Sphere(0.008), Rgba(0, 1, 0, 1.0))\n",
    "            meshcat.SetTransform(f\"perception/red_pt_{i}\", RigidTransform(red_points[i]))\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(f\"✓ DETECTED RED BALL - Error: {error*1000:.1f}mm\")\n",
    "        print(\"=\"*60)\n",
    "    else:\n",
    "        detected_red_pos = None\n",
    "        print(\"✗ Too few red points for clustering\")\n",
    "else:\n",
    "    detected_red_pos = None\n",
    "    print(\"✗ No elevated points found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cell-5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TRAJECTORY PLANNING ===\n",
      "Target ball: [-0.00219639 -0.50580673  0.05      ]\n",
      "Grasp pose: [-0.00219639 -0.50580673  0.17      ]\n",
      "Throw target: [0. 1. 0.]\n",
      "\n",
      "Solving IK for pick trajectory...\n",
      "Pick trajectory: 2.50s\n",
      "\n",
      "Full trajectory: 4.40s\n",
      "  Pick: 0 - 2.50s\n",
      "  Move to prethrow: 2.50 - 4.00s\n",
      "  Throw: 4.00 - 4.40s\n",
      "  Release at: 4.20s\n"
     ]
    }
   ],
   "source": [
    "# TRAJECTORY PLANNING: Pick + Throw\n",
    "\n",
    "if detected_red_pos is None:\n",
    "    raise RuntimeError(\"Cannot plan trajectory - no ball detected\")\n",
    "\n",
    "print(\"=== TRAJECTORY PLANNING ===\")\n",
    "\n",
    "# Grasp parameters\n",
    "GRIPPER_OPEN = 0.107\n",
    "GRIPPER_CLOSED = 0.0\n",
    "GRASP_HEIGHT = 0.12\n",
    "APPROACH_HEIGHT = 0.1\n",
    "\n",
    "# Target for throwing\n",
    "P_TARGET = np.array([0, 1.0, 0.0])\n",
    "RELEASE_FRAC = 0.5\n",
    "THROW_DURATION = 0.4\n",
    "\n",
    "def design_grasp_pose(X_WO: RigidTransform) -> RigidTransform:\n",
    "    \"\"\"Grasp pose above object with gripper pointing down.\"\"\"\n",
    "    return X_WO @ RigidTransform(RotationMatrix.MakeXRotation(-np.pi/2), [0, 0, GRASP_HEIGHT])\n",
    "\n",
    "# Ball pose from perception\n",
    "X_WBall = RigidTransform(p=detected_red_pos)\n",
    "\n",
    "# Pick trajectory poses\n",
    "X_WG_grasp = design_grasp_pose(X_WBall)\n",
    "X_WG_approach = RigidTransform(p=[0, 0, APPROACH_HEIGHT]) @ X_WG_grasp\n",
    "\n",
    "print(f\"Target ball: {detected_red_pos}\")\n",
    "print(f\"Grasp pose: {X_WG_grasp.translation()}\")\n",
    "print(f\"Throw target: {P_TARGET}\")\n",
    "\n",
    "# Pick timing\n",
    "t_approach = 1.0\n",
    "t_descend = 0.5\n",
    "t_grasp = 0.5\n",
    "t_lift = 0.5\n",
    "\n",
    "t0, t1, t2, t3, t4 = 0, t_approach, t_approach + t_descend, t_approach + t_descend + t_grasp, t_approach + t_descend + t_grasp + t_lift\n",
    "\n",
    "# Create pick pose trajectory\n",
    "pose_traj = PiecewisePose.MakeLinear(\n",
    "    [t0, t1, t2, t3, t4],\n",
    "    [X_WG_initial, X_WG_approach, X_WG_grasp, X_WG_grasp, X_WG_approach]\n",
    ")\n",
    "\n",
    "# Gripper trajectory for pick\n",
    "pick_gripper_traj = PiecewisePolynomial.FirstOrderHold(\n",
    "    [t0, t1, t2, t3, t4],\n",
    "    np.array([[GRIPPER_OPEN, GRIPPER_OPEN, GRIPPER_OPEN, GRIPPER_CLOSED, GRIPPER_CLOSED]])\n",
    ")\n",
    "\n",
    "# Convert pick poses to joint angles\n",
    "print(\"\\nSolving IK for pick trajectory...\")\n",
    "num_samples = 50\n",
    "t_samples = np.linspace(t0, t4, num_samples)\n",
    "poses = [pose_traj.GetPose(t) for t in t_samples]\n",
    "q_pick_knots = create_q_knots(plant, poses)\n",
    "q_pick_traj = PiecewisePolynomial.CubicShapePreserving(t_samples[:len(q_pick_knots)], np.array(q_pick_knots).T)\n",
    "print(f\"Pick trajectory: {q_pick_traj.end_time():.2f}s\")\n",
    "\n",
    "# Throw trajectory\n",
    "throw_heading = np.arctan2(P_TARGET[1], P_TARGET[0])\n",
    "ja1 = throw_heading - np.pi\n",
    "\n",
    "PRETHROW_JA = np.array([ja1, 0, 0, 1.9, 0, -1.9, np.pi])\n",
    "THROWEND_JA = np.array([ja1, 0, 0, 0.4, 0, -0.4, np.pi])\n",
    "\n",
    "q_postpick = q_pick_traj.value(q_pick_traj.end_time()).flatten()\n",
    "\n",
    "def interpolate_joint_angles(ja_start, ja_end, duration, num_samples):\n",
    "    t_samples = np.linspace(0, duration, num_samples, endpoint=True)\n",
    "    q_samples = [ja_start + (t / duration) * (ja_end - ja_start) for t in t_samples]\n",
    "    return t_samples, q_samples\n",
    "\n",
    "t_throw_samples, q_throw_samples = interpolate_joint_angles(PRETHROW_JA, THROWEND_JA, THROW_DURATION, 30)\n",
    "\n",
    "# Combine pick + throw trajectories\n",
    "T_GO_TO_PRETHROW = 1.5\n",
    "t_pick_end = q_pick_traj.end_time()\n",
    "\n",
    "t_full = list(np.linspace(0, t_pick_end, 50))\n",
    "t_full += [t_pick_end + T_GO_TO_PRETHROW]\n",
    "t_full += list(t_pick_end + T_GO_TO_PRETHROW + t_throw_samples[1:])\n",
    "\n",
    "q_full = [q_pick_traj.value(t).flatten() for t in np.linspace(0, t_pick_end, 50)]\n",
    "q_full += [PRETHROW_JA] + q_throw_samples[1:]\n",
    "\n",
    "q_full_traj = PiecewisePolynomial.CubicShapePreserving(t_full, np.array(q_full).T)\n",
    "\n",
    "# Full gripper trajectory: open -> close at grasp -> open at release\n",
    "t_grasp_close = t3  # When gripper closes during pick\n",
    "t_release = t_pick_end + T_GO_TO_PRETHROW + RELEASE_FRAC * THROW_DURATION\n",
    "\n",
    "g_full_traj = PiecewisePolynomial.FirstOrderHold(\n",
    "    [0, t_grasp_close, t_grasp_close + 0.01, t_release, t_release + 0.01, q_full_traj.end_time()],\n",
    "    np.array([[GRIPPER_OPEN, GRIPPER_OPEN, GRIPPER_CLOSED, GRIPPER_CLOSED, GRIPPER_OPEN, GRIPPER_OPEN]])\n",
    ")\n",
    "\n",
    "print(f\"\\nFull trajectory: {q_full_traj.end_time():.2f}s\")\n",
    "print(f\"  Pick: 0 - {t_pick_end:.2f}s\")\n",
    "print(f\"  Move to prethrow: {t_pick_end:.2f} - {t_pick_end + T_GO_TO_PRETHROW:.2f}s\")\n",
    "print(f\"  Throw: {t_pick_end + T_GO_TO_PRETHROW:.2f} - {q_full_traj.end_time():.2f}s\")\n",
    "print(f\"  Release at: {t_release:.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cell-6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== PHYSICS SIMULATION ===\n",
      "Running simulation...\n",
      "  Gripper closes at t=2.00s\n",
      "  Release at t=4.20s\n",
      "\n",
      "============================================================\n",
      "SIMULATION COMPLETE!\n",
      "  Detected ball at: [-0.00219639 -0.50580673  0.05      ]\n",
      "  Threw towards: [0. 1. 0.]\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# EXECUTE: Full pick + throw with physics simulation\n",
    "\n",
    "print(\"=== PHYSICS SIMULATION ===\")\n",
    "\n",
    "meshcat.Delete()\n",
    "\n",
    "# Rebuild diagram with trajectory sources\n",
    "builder2 = DiagramBuilder()\n",
    "scenario2 = LoadScenario(data=scenario_yaml)\n",
    "station2 = MakeHardwareStation(scenario2, meshcat=meshcat)\n",
    "builder2.AddSystem(station2)\n",
    "full_plant = station2.GetSubsystemByName(\"plant\")\n",
    "\n",
    "# Add triads for visualization\n",
    "AddMeshcatTriad(meshcat, \"target\", length=0.2, radius=0.01, X_PT=RigidTransform(p=P_TARGET))\n",
    "AddMeshcatTriad(meshcat, \"prethrow\", length=0.12, radius=0.005, X_PT=joint_angles_to_pose(full_plant, PRETHROW_JA))\n",
    "AddMeshcatTriad(meshcat, \"throwend\", length=0.12, radius=0.005, X_PT=joint_angles_to_pose(full_plant, THROWEND_JA))\n",
    "\n",
    "# Connect trajectory sources\n",
    "q_source = builder2.AddSystem(TrajectorySource(q_full_traj))\n",
    "g_source = builder2.AddSystem(TrajectorySource(g_full_traj))\n",
    "\n",
    "builder2.Connect(q_source.get_output_port(), station2.GetInputPort(\"iiwa.position\"))\n",
    "builder2.Connect(g_source.get_output_port(), station2.GetInputPort(\"wsg.position\"))\n",
    "\n",
    "diagram2 = builder2.Build()\n",
    "\n",
    "# Run simulation\n",
    "simulator = Simulator(diagram2)\n",
    "simulator.set_target_realtime_rate(1.0)\n",
    "\n",
    "print(f\"Running simulation...\")\n",
    "print(f\"  Gripper closes at t={t_grasp_close:.2f}s\")\n",
    "print(f\"  Release at t={t_release:.2f}s\")\n",
    "\n",
    "meshcat.StartRecording()\n",
    "simulator.AdvanceTo(q_full_traj.end_time() + 2.0)\n",
    "meshcat.StopRecording()\n",
    "meshcat.PublishRecording()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SIMULATION COMPLETE!\")\n",
    "print(f\"  Detected ball at: {detected_red_pos}\")\n",
    "print(f\"  Threw towards: {P_TARGET}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6cae7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
